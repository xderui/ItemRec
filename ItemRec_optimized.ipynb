{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load scores tensor (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>844</th>\n",
       "      <th>845</th>\n",
       "      <th>846</th>\n",
       "      <th>847</th>\n",
       "      <th>848</th>\n",
       "      <th>849</th>\n",
       "      <th>850</th>\n",
       "      <th>851</th>\n",
       "      <th>852</th>\n",
       "      <th>853</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.331406</td>\n",
       "      <td>0.280178</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>5.195839e-01</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>0.402708</td>\n",
       "      <td>4.867731e-01</td>\n",
       "      <td>0.474337</td>\n",
       "      <td>0.422230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630990</td>\n",
       "      <td>0.333921</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>0.073853</td>\n",
       "      <td>0.651333</td>\n",
       "      <td>0.438040</td>\n",
       "      <td>0.441256</td>\n",
       "      <td>0.334835</td>\n",
       "      <td>0.360692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.290129</td>\n",
       "      <td>0.304653</td>\n",
       "      <td>4.168867e-01</td>\n",
       "      <td>5.879234e-01</td>\n",
       "      <td>4.549532e-01</td>\n",
       "      <td>4.588683e-01</td>\n",
       "      <td>0.399067</td>\n",
       "      <td>5.706309e-01</td>\n",
       "      <td>0.446806</td>\n",
       "      <td>0.424417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546390</td>\n",
       "      <td>0.314037</td>\n",
       "      <td>6.225903e-01</td>\n",
       "      <td>5.334495e-01</td>\n",
       "      <td>0.098213</td>\n",
       "      <td>0.589729</td>\n",
       "      <td>0.393379</td>\n",
       "      <td>0.410857</td>\n",
       "      <td>0.329335</td>\n",
       "      <td>0.430018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.345323</td>\n",
       "      <td>0.210515</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>5.592080e-01</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>6.397491e-01</td>\n",
       "      <td>0.388027</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>0.482791</td>\n",
       "      <td>0.393186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493282</td>\n",
       "      <td>0.323248</td>\n",
       "      <td>4.366275e-01</td>\n",
       "      <td>4.932338e-01</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>0.414490</td>\n",
       "      <td>0.524191</td>\n",
       "      <td>0.377856</td>\n",
       "      <td>0.373770</td>\n",
       "      <td>0.383036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.335566</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>3.918142e-01</td>\n",
       "      <td>5.505714e-01</td>\n",
       "      <td>4.457762e-01</td>\n",
       "      <td>4.060564e-01</td>\n",
       "      <td>0.414192</td>\n",
       "      <td>4.799969e-01</td>\n",
       "      <td>0.469270</td>\n",
       "      <td>0.398371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443196</td>\n",
       "      <td>0.268232</td>\n",
       "      <td>4.646194e-01</td>\n",
       "      <td>4.701371e-01</td>\n",
       "      <td>0.149726</td>\n",
       "      <td>0.468727</td>\n",
       "      <td>0.362499</td>\n",
       "      <td>0.419989</td>\n",
       "      <td>0.346085</td>\n",
       "      <td>0.438212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.316109</td>\n",
       "      <td>0.324808</td>\n",
       "      <td>4.062611e-01</td>\n",
       "      <td>5.064892e-01</td>\n",
       "      <td>4.199317e-01</td>\n",
       "      <td>3.910332e-01</td>\n",
       "      <td>0.390788</td>\n",
       "      <td>4.642188e-01</td>\n",
       "      <td>0.458737</td>\n",
       "      <td>0.393376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421836</td>\n",
       "      <td>0.189362</td>\n",
       "      <td>4.275019e-01</td>\n",
       "      <td>4.826458e-01</td>\n",
       "      <td>0.191160</td>\n",
       "      <td>0.449492</td>\n",
       "      <td>0.363881</td>\n",
       "      <td>0.375864</td>\n",
       "      <td>0.323614</td>\n",
       "      <td>0.416821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>0.420022</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>4.852486e-01</td>\n",
       "      <td>4.730469e-01</td>\n",
       "      <td>3.523092e-01</td>\n",
       "      <td>5.205200e-01</td>\n",
       "      <td>0.268604</td>\n",
       "      <td>4.395292e-01</td>\n",
       "      <td>0.296861</td>\n",
       "      <td>0.482562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341211</td>\n",
       "      <td>0.481065</td>\n",
       "      <td>4.170464e-01</td>\n",
       "      <td>4.659184e-01</td>\n",
       "      <td>0.303879</td>\n",
       "      <td>0.336407</td>\n",
       "      <td>0.566173</td>\n",
       "      <td>0.279829</td>\n",
       "      <td>0.479844</td>\n",
       "      <td>0.526327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>0.384294</td>\n",
       "      <td>0.398105</td>\n",
       "      <td>4.601306e-01</td>\n",
       "      <td>5.583086e-01</td>\n",
       "      <td>4.251068e-01</td>\n",
       "      <td>5.981378e-01</td>\n",
       "      <td>0.345325</td>\n",
       "      <td>4.813348e-01</td>\n",
       "      <td>0.396453</td>\n",
       "      <td>0.416362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491878</td>\n",
       "      <td>0.343988</td>\n",
       "      <td>5.097014e-01</td>\n",
       "      <td>5.010271e-01</td>\n",
       "      <td>0.360509</td>\n",
       "      <td>0.464977</td>\n",
       "      <td>0.508359</td>\n",
       "      <td>0.402585</td>\n",
       "      <td>0.402791</td>\n",
       "      <td>0.453156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>0.199680</td>\n",
       "      <td>0.197117</td>\n",
       "      <td>5.266573e-01</td>\n",
       "      <td>5.236182e-01</td>\n",
       "      <td>3.681665e-01</td>\n",
       "      <td>3.835050e-01</td>\n",
       "      <td>0.416929</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>0.384005</td>\n",
       "      <td>0.368110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439530</td>\n",
       "      <td>0.369540</td>\n",
       "      <td>4.629174e-01</td>\n",
       "      <td>4.976031e-01</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.393458</td>\n",
       "      <td>0.424172</td>\n",
       "      <td>0.382394</td>\n",
       "      <td>0.330114</td>\n",
       "      <td>0.344768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>0.260489</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>4.592009e-01</td>\n",
       "      <td>5.049434e-01</td>\n",
       "      <td>4.797631e-01</td>\n",
       "      <td>3.706224e-01</td>\n",
       "      <td>0.489580</td>\n",
       "      <td>5.669957e-01</td>\n",
       "      <td>0.423839</td>\n",
       "      <td>0.427352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659947</td>\n",
       "      <td>0.372320</td>\n",
       "      <td>7.461454e-01</td>\n",
       "      <td>4.634248e-01</td>\n",
       "      <td>-0.074940</td>\n",
       "      <td>0.657177</td>\n",
       "      <td>0.381077</td>\n",
       "      <td>0.379598</td>\n",
       "      <td>0.297279</td>\n",
       "      <td>0.355750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>0.175192</td>\n",
       "      <td>0.300372</td>\n",
       "      <td>4.458593e-01</td>\n",
       "      <td>4.976796e-01</td>\n",
       "      <td>4.422295e-01</td>\n",
       "      <td>3.950978e-01</td>\n",
       "      <td>0.361973</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>0.592082</td>\n",
       "      <td>0.322620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410349</td>\n",
       "      <td>0.165819</td>\n",
       "      <td>5.040421e-01</td>\n",
       "      <td>-1.000000e+08</td>\n",
       "      <td>0.286207</td>\n",
       "      <td>0.502330</td>\n",
       "      <td>0.357207</td>\n",
       "      <td>0.311408</td>\n",
       "      <td>0.260744</td>\n",
       "      <td>0.344017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1510 rows Ã— 854 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1             2             3             4    \\\n",
       "0     0.331406  0.280178 -1.000000e+08 -1.000000e+08  5.195839e-01   \n",
       "1     0.290129  0.304653  4.168867e-01  5.879234e-01  4.549532e-01   \n",
       "2     0.345323  0.210515 -1.000000e+08  5.592080e-01 -1.000000e+08   \n",
       "3     0.335566  0.313333  3.918142e-01  5.505714e-01  4.457762e-01   \n",
       "4     0.316109  0.324808  4.062611e-01  5.064892e-01  4.199317e-01   \n",
       "...        ...       ...           ...           ...           ...   \n",
       "1505  0.420022  0.444244  4.852486e-01  4.730469e-01  3.523092e-01   \n",
       "1506  0.384294  0.398105  4.601306e-01  5.583086e-01  4.251068e-01   \n",
       "1507  0.199680  0.197117  5.266573e-01  5.236182e-01  3.681665e-01   \n",
       "1508  0.260489  0.245708  4.592009e-01  5.049434e-01  4.797631e-01   \n",
       "1509  0.175192  0.300372  4.458593e-01  4.976796e-01  4.422295e-01   \n",
       "\n",
       "               5         6             7         8         9    ...       844  \\\n",
       "0    -1.000000e+08  0.402708  4.867731e-01  0.474337  0.422230  ...  0.630990   \n",
       "1     4.588683e-01  0.399067  5.706309e-01  0.446806  0.424417  ...  0.546390   \n",
       "2     6.397491e-01  0.388027 -1.000000e+08  0.482791  0.393186  ...  0.493282   \n",
       "3     4.060564e-01  0.414192  4.799969e-01  0.469270  0.398371  ...  0.443196   \n",
       "4     3.910332e-01  0.390788  4.642188e-01  0.458737  0.393376  ...  0.421836   \n",
       "...            ...       ...           ...       ...       ...  ...       ...   \n",
       "1505  5.205200e-01  0.268604  4.395292e-01  0.296861  0.482562  ...  0.341211   \n",
       "1506  5.981378e-01  0.345325  4.813348e-01  0.396453  0.416362  ...  0.491878   \n",
       "1507  3.835050e-01  0.416929 -1.000000e+08  0.384005  0.368110  ...  0.439530   \n",
       "1508  3.706224e-01  0.489580  5.669957e-01  0.423839  0.427352  ...  0.659947   \n",
       "1509  3.950978e-01  0.361973 -1.000000e+08  0.592082  0.322620  ...  0.410349   \n",
       "\n",
       "           845           846           847       848       849       850  \\\n",
       "0     0.333921 -1.000000e+08 -1.000000e+08  0.073853  0.651333  0.438040   \n",
       "1     0.314037  6.225903e-01  5.334495e-01  0.098213  0.589729  0.393379   \n",
       "2     0.323248  4.366275e-01  4.932338e-01  0.139200  0.414490  0.524191   \n",
       "3     0.268232  4.646194e-01  4.701371e-01  0.149726  0.468727  0.362499   \n",
       "4     0.189362  4.275019e-01  4.826458e-01  0.191160  0.449492  0.363881   \n",
       "...        ...           ...           ...       ...       ...       ...   \n",
       "1505  0.481065  4.170464e-01  4.659184e-01  0.303879  0.336407  0.566173   \n",
       "1506  0.343988  5.097014e-01  5.010271e-01  0.360509  0.464977  0.508359   \n",
       "1507  0.369540  4.629174e-01  4.976031e-01  0.004933  0.393458  0.424172   \n",
       "1508  0.372320  7.461454e-01  4.634248e-01 -0.074940  0.657177  0.381077   \n",
       "1509  0.165819  5.040421e-01 -1.000000e+08  0.286207  0.502330  0.357207   \n",
       "\n",
       "           851       852       853  \n",
       "0     0.441256  0.334835  0.360692  \n",
       "1     0.410857  0.329335  0.430018  \n",
       "2     0.377856  0.373770  0.383036  \n",
       "3     0.419989  0.346085  0.438212  \n",
       "4     0.375864  0.323614  0.416821  \n",
       "...        ...       ...       ...  \n",
       "1505  0.279829  0.479844  0.526327  \n",
       "1506  0.402585  0.402791  0.453156  \n",
       "1507  0.382394  0.330114  0.344768  \n",
       "1508  0.379598  0.297279  0.355750  \n",
       "1509  0.311408  0.260744  0.344017  \n",
       "\n",
       "[1510 rows x 854 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "model_name = 'SimpleX'\n",
    "data_name = 'ml-1m'\n",
    "\n",
    "# scores_tensor_df = pd.read_csv(f'./pretrained_scores/{data_name}/{model_name}_{data_name}_scores_tensor.csv', header=None)\n",
    "scores_tensor_df = pd.read_csv(f'./pretrained_scores/{data_name}/{model_name}_{data_name}_scores_tensor.txt', header=None)\n",
    "scores_tensor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ItemRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain, repeat\n",
    "\n",
    "limit_num = 50\n",
    "topk = 10\n",
    "item_limit_num = 5\n",
    "# scores_tensor_df = scores_tensor_df.iloc[:,:]\n",
    "\n",
    "scores_tensor = torch.tensor(scores_tensor_df.to_numpy())\n",
    "scores_sorted, idx_sorted = torch.sort(scores_tensor, dim=-1, descending=True)\n",
    "\n",
    "scores_tensor = scores_sorted[:,:limit_num]\n",
    "scores_tensor_user = idx_sorted[:,:limit_num]\n",
    "\n",
    "\n",
    "item_list = scores_tensor_user.flatten()\n",
    "user_list = np.tile(np.arange(scores_tensor.shape[0]).reshape(-1,1),limit_num).flatten()\n",
    "scores_list = scores_tensor.flatten()\n",
    "idx_item_list = np.tile(np.arange(limit_num).reshape(1,-1), (scores_tensor.shape[0],1)).flatten()\n",
    "user_item_df = pd.DataFrame({'uid':user_list, 'iid':item_list, 'idx_item':idx_item_list, 'score':scores_list})\n",
    "\n",
    "# general top-k recommendation results\n",
    "top_k_item_origin = user_item_df.sort_values(by=['uid', 'score'],ascending=[True, False]).groupby('uid',sort=False).head(topk).loc[:,['uid','iid','score']]\n",
    "\n",
    "\n",
    "# get maximum and minimum score of each item\n",
    "user_item_df = user_item_df.sort_values(by='iid')\n",
    "item_norm_scores_g = user_item_df.groupby(by='iid',sort=False)\n",
    "item_scores_max, item_scores_min = item_norm_scores_g.max()['score'].tolist(), item_norm_scores_g.min()['score'].tolist()\n",
    "uid_list_len = item_norm_scores_g.count().iloc[:,0].tolist()\n",
    "\n",
    "user_item_df['min_score'] = list(chain(*[list(repeat(s,uid_len)) for s, uid_len in zip(item_scores_min, uid_list_len)]))\n",
    "user_item_df['max_score'] = list(chain(*[list(repeat(s,uid_len)) for s, uid_len in zip(item_scores_max, uid_list_len)]))\n",
    "\n",
    "\n",
    "# item's rank in user\n",
    "user_item_df['rank_item'] = user_item_df['idx_item'] - (user_item_df['score'] - user_item_df['min_score']) / (user_item_df['max_score'] - user_item_df['min_score'])\n",
    "\n",
    "# user's rank in item\n",
    "user_item_df = user_item_df.sort_values(by=['iid','rank_item'])\n",
    "top_kitem_user = user_item_df.groupby('iid',sort=False).head(item_limit_num).loc[:,['uid','iid','score']]\n",
    "\n",
    "# trans to user-item\n",
    "\n",
    "uid_idx_ = list(chain(*[list(range(u_len)) for u_len in uid_list_len]))\n",
    "uid_len_ = list(chain(*[list(repeat(uid_len,uid_len)) for uid_len in uid_list_len]))\n",
    "user_item_df['uid_len'] = uid_len_\n",
    "user_item_df['idx_user'] = uid_idx_\n",
    "user_item_df['rank_user'] = user_item_df['idx_user'] + 1/user_item_df['uid_len']\n",
    "\n",
    "\n",
    "# user-item sort\n",
    "user_item_df = user_item_df.sort_values(by=['uid','rank_user'])\n",
    "top_k_item = user_item_df.groupby('uid',sort=False).head(topk).loc[:,['uid','iid','score']]\n",
    "\n",
    "# top_k_item\n",
    "final_df = pd.merge(left=top_k_item, right=top_kitem_user, left_on=['uid','iid'], right_on=['uid','iid'],how='inner')\n",
    "final_df = pd.merge(left=final_df, right=top_k_item_origin, left_on=['uid','iid'], right_on=['uid','iid'], how='outer')\n",
    "final_df = final_df.groupby(by='uid',sort=False).head(10).sort_values(by=['uid','score'],ascending=[True,False])\n",
    "topk_idx = torch.tensor(final_df['iid'].tolist()).cuda().reshape(scores_tensor.shape[0], topk)\n",
    "topk_idx2 = torch.tensor(top_k_item_origin['iid'].tolist()).cuda().reshape(scores_tensor.shape[0], topk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load data\n",
    "path = f'./datasets/{data_name}/{data_name}-dataset_test.txt'\n",
    "test_df = pd.read_csv(path, header=None)\n",
    "test_user_list = defaultdict(list)\n",
    "for i,x in test_df.iterrows():\n",
    "    test_user_list[x[0]].append(x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2939110070257611, 0.25878220140515223)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_coverage = set()\n",
    "valid_coverage_topk2 = set()\n",
    "for uid in range(topk_idx.shape[0]):\n",
    "    valid_coverage = valid_coverage | set(topk_idx[uid].tolist()) & set(test_user_list[uid])\n",
    "    valid_coverage_topk2 = valid_coverage_topk2 | set(topk_idx2[uid].tolist()) & set(test_user_list[uid])\n",
    "\n",
    "\n",
    "item_num = scores_tensor_df.shape[1]\n",
    "\n",
    "valid_coverage = len(valid_coverage) / item_num\n",
    "valid_coverage_topk2 = len(valid_coverage_topk2) / item_num\n",
    "valid_coverage, valid_coverage_topk2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08647759, 0.09061509)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_len = []\n",
    "for u in range(topk_idx.shape[0]):\n",
    "    pos_len.append(len(test_user_list[u]))\n",
    "\n",
    "pos_index = np.zeros(topk_idx.shape)\n",
    "pos_index2 = np.zeros(topk_idx2.shape)\n",
    "\n",
    "for u in range(topk_idx.shape[0]):\n",
    "    for j in range(topk):\n",
    "        if topk_idx[u,j].item() in test_user_list[u]:\n",
    "            pos_index[u,j] = 1\n",
    "        \n",
    "        if topk_idx2[u,j].item() in test_user_list[u]:\n",
    "            pos_index2[u,j] = 1\n",
    "\n",
    "\n",
    "len_rank = np.full_like(pos_len, pos_index.shape[1])\n",
    "idcg_len = np.where(pos_len > len_rank, len_rank, pos_len)\n",
    "iranks = np.zeros_like(pos_index, dtype=np.float32)\n",
    "iranks[:, :] = np.arange(1, pos_index.shape[1] + 1)\n",
    "idcg = np.cumsum(1.0 / np.log2(iranks + 1), axis=1)\n",
    "for row, idx in enumerate(idcg_len):\n",
    "    idcg[row, idx:] = idcg[row, idx - 1]\n",
    "\n",
    "ranks = np.zeros_like(pos_index, dtype=np.float32)\n",
    "ranks[:, :] = np.arange(1, pos_index.shape[1] + 1)\n",
    "dcg = 1.0 / np.log2(ranks + 1)\n",
    "dcg = np.cumsum(np.where(pos_index, dcg, 0), axis=1)\n",
    "ndcg = dcg / idcg\n",
    "\n",
    "\n",
    "iranks2 = np.zeros_like(pos_index2, dtype=np.float32)\n",
    "iranks2[:, :] = np.arange(1, pos_index2.shape[1] + 1)\n",
    "idcg2 = np.cumsum(1.0 / np.log2(iranks2 + 1), axis=1)\n",
    "for row, idx in enumerate(idcg_len):\n",
    "    idcg2[row, idx:] = idcg2[row, idx - 1]\n",
    "\n",
    "ranks2 = np.zeros_like(pos_index2, dtype=np.float32)\n",
    "ranks2[:, :] = np.arange(1, pos_index2.shape[1] + 1)\n",
    "dcg2 = 1.0 / np.log2(ranks2 + 1)\n",
    "dcg2 = np.cumsum(np.where(pos_index2, dcg2, 0), axis=1)\n",
    "ndcg2 = dcg2 / idcg2\n",
    "\n",
    "np.mean(ndcg,axis=0)[-1], np.mean(ndcg2,axis=0)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7508235494827613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = [0 for i in range(item_num)]\n",
    "row, col = topk_idx.shape\n",
    "for i in range(row):\n",
    "    for j in range(col):\n",
    "        cnt[topk_idx[i,j].item()] += 1\n",
    "\n",
    "cnt.sort()\n",
    "giny = 0\n",
    "height, area = 0, 0\n",
    "for c in cnt:\n",
    "    height += c\n",
    "    area += height-c/2\n",
    "fair_area = height*item_num/2\n",
    "giny = (fair_area-area)/fair_area\n",
    "giny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpfair",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
